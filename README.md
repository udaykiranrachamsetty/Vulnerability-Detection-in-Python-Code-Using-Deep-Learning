# Deep Learning-based Vulnerability Detection in Python Codebase

The main aim of this project is to find vulnerabilities in a Python codebase. Our approach involves employing Word2Vec for embedding and Long Short Term Memory (LSTM) networks for extracting features.

## CODE

### 1. Training Word2Vec Model
The Word2Vec model is trained using a large dataset of Python code that is simply combined.

#### Step 1.1 Cleaning the Dataset

[Python Code Dataset from Zenodo](https://zenodo.org/records/3559480#.XeTMzdVG2Hs)

`cleaning.py` is designed for cleaning up and refactoring a Python codebase. It reads a `pythontraining.txt` file, identifies specific problematic code patterns, and either removes or modifies these segments to enhance the code's quality and maintainability.

- **Tab to Space Conversion**: Converts tab characters in the code to four spaces for consistent indentation.
- **Pattern Removal and Modification**: Removes or modifies specific code patterns that are identified as problematic.
- **Context-Sensitive Editing**: Makes changes within the context of the code, such as within specific classes or functions, to ensure appropriate modifications.

#### Step 1.2 Tokenize the dataset 

`tokenize.py` is used for tokenizing the cleaned data from the previous step. we use python in-built `tokenize` . 
- To manage the large dataset efficiently, the tokenization output is divided into multiple smaller files, enhancing ease of use and memory efficiency.
- After the initial processing, these smaller files are merged back into a single file to consolidate the tokenized data, facilitating easier analysis and further processing.

#### Step 1.3 Training Word2Vec Model

The script loads a text corpus from a specified file, processes it using NLTK for tokenization into sentences and words, and then trains a Word2Vec model from the Gensim library using the tokenized data. The training parameters include minimum count, number of iterations, and vector size.

- **Minimum Count**: 10
- **Number of Iterations**: 100
- **Vector Size**: 200





