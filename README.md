# Deep Learning-based Vulnerability Detection in Python Codebase

The main aim of this project is to find vulnerabilities in a Python codebase. Our approach involves employing Word2Vec for embedding and Long Short Term Memory (LSTM) networks for extracting features.

## CODE

### 1. Training Word2Vec Model
The Word2Vec model is trained using a large dataset of Python code that is simply combined.

#### Step 1.1 Cleaning the Dataset

[Python Code Dataset from Zenodo](https://zenodo.org/records/3559480#.XeTMzdVG2Hs)

`cleaning.py` is designed for cleaning up and refactoring a Python codebase. It reads a `pythontraining.txt` file, identifies specific problematic code patterns, and either removes or modifies these segments to enhance the code's quality and maintainability.

- **Tab to Space Conversion**: Converts tab characters in the code to four spaces for consistent indentation.
- **Pattern Removal and Modification**: Removes or modifies specific code patterns that are identified as problematic.
- **Context-Sensitive Editing**: Makes changes within the context of the code, such as within specific classes or functions, to ensure appropriate modifications.

#### Step 1.2 Tokenize the dataset 

`tokenize.py` is used for tokenizing the cleaned data from the previous step. we use python in-built `tokenize` . 
- To manage the large dataset efficiently, the tokenization output is divided into multiple smaller files, enhancing ease of use and memory efficiency.
- After the initial processing, these smaller files are merged back into a single file to consolidate the tokenized data, facilitating easier analysis and further processing.

#### Step 1.3 Training Word2Vec Model

The script loads a text corpus from a specified file, processes it using NLTK for tokenization into sentences and words, and then trains a Word2Vec model from the Gensim library using the tokenized data. The training parameters include minimum count, number of iterations, and vector size.

- **Minimum Count**: 10
- **Number of Iterations**: 100
- **Vector Size**: 200


### 2. Training LSTM MODEL
#### Step 2.1 Labeling of Dataset
`plain_sql` is the dataset , it contains the data from 336 github repositories. First we find the positions of comments(start and end index) in the source code , and then the position of bad parts (vulnerable parts ) and then take a small focus area and consider a context area(max of 200 length) around it and then if the context block intercepts with vulnerable part then we mark it as a vulnerable block and if not intersecting not vulnerable. 
you can refer to the below image
![Labeling Process](https://github.com/udaykiranrachamsetty/Vulnerability-Detection-in-Python-Code-Using-Deep-Learning/blob/master/Images/LabelingProcess.png)
In the image orange/red part is vulnerable piece code of code blue part is the focus area we are considering.

#### Step 2.2 Processing data
after labeling , we need to convert the blocks into numericals , here we use the trainined Word2Vec Model and we convert each token in the block into the vectors.

#### Step 2.3 LSTM MODEL
finally training lstm model, you can go through the .ipynb files i provided , which contains model configurations.

### 3. Pinpointing Result
![Predicting Process](https://github.com/udaykiranrachamsetty/Vulnerability-Detection-in-Python-Code-Using-Deep-Learning/blob/master/Images/ColuringProcess.png)
User enters a python code , similar to the labeling process , it takes a small focus area and take context around it and we convert the blocks into vectors using the training Word2Vec model and predict whether the block is vulnerable or not . According to the prediction we will colour the block. The Thresholds and the coloring process is given below:
![Thresholds and Colours](https://github.com/udaykiranrachamsetty/Vulnerability-Detection-in-Python-Code-Using-Deep-Learning/blob/master/Images/coluring.png).

we can use flask or streamlit for the interface.





