import os
import pickle
import sys
import re
from gensim.models import Word2Vec
from itertools import product

def load_corpus(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        return file.read().lower().replace('\n', ' ')

def simple_tokenize(text):
    # Tokenize the text using regular expressions
    return re.findall(r'\b\w+\b', text)

def prepare_data(file_path, processed_path):
    if os.path.isfile(processed_path):
        with open(processed_path, 'rb') as fp:
            print("Loaded processed data.")
            return pickle.load(fp)
    else:
        print("Now processing...")
        processed_data = simple_tokenize(load_corpus(file_path))
        print("Saving processed data...")
        with open(processed_path, 'wb') as fp:
            pickle.dump(processed_data, fp)
        return processed_data

def train_word2vec_models(all_words, combinations, mode):
    for min_count, iterations, size in combinations:
        print(f"\n\n{mode} W2V model with min count {min_count} and {iterations} iterations and size {size}")
        model_file_name = f"word2vec/word2vec_{mode}{min_count}-{iterations}-{size}.model"
        if not os.path.isfile(model_file_name):
            print("Calculating model...")
            # Ensure the directory exists
            os.makedirs(os.path.dirname(model_file_name), exist_ok=True)
            model = Word2Vec([all_words], vector_size=size, min_count=min_count, epochs=iterations, workers=4)
            model.save(model_file_name)
            print(f"Model saved as {model_file_name}")
        else:
            print("Model already exists.")

def main():
    mode = sys.argv[1] if len(sys.argv) > 1 else "withString"
    print(f"Loading {mode}")

    file_path = f'pythontraining_withString_X'
    processed_path = f'data/pythontraining_processed_{mode}'

    all_words = prepare_data(file_path, processed_path)
    print(f"Length of the training file: {len(' '.join(all_words))}.")
    print(f"It contains {len(all_words)} individual code tokens.")

    # Generate all possible combinations of min_count, iterations, and size
    min_count_values = [10, 30, 50, 100, 300, 500, 5000]
    iterations_values = [1, 5, 10, 30, 50, 100]
    size_values = [5, 10, 15, 30, 50, 75, 100, 200, 300]
    combinations = list(product(min_count_values, iterations_values, size_values))

    train_word2vec_models(all_words, combinations, mode)

if __name__ == "__main__":
    main()
