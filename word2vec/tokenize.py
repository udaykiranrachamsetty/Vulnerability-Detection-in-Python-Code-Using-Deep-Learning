import sys
import subprocess
import io

pythondata = ""

mode = "withString"  # default
# mode = "withoutString"

if len(sys.argv) > 1:
    mode = sys.argv[1]

# Use the python tokenizer to tokenize the words in the corpus
p = subprocess.Popen(["python", "-m", "tokenize", "pythontraining" + "_edit.txt"], stdout=subprocess.PIPE)
out, err = p.communicate()

s = io.StringIO(out.decode('utf-8'))  # Corrected usage of StringIO here
count = 0
totalcount = 0
comment = 0
part = 0

for line in s:
    totalcount += 1
    count += 1
    if totalcount % 1000 == 0:
        print(totalcount)
    position1 = line.find(":") + 1
    position2 = line.find("'")
    position3 = line[position2 + 1:].find("'")

    cat = line[position1:position2]
    content = line[position2 + 1:-2]

    if '"""' in line:
        comment += 1
        continue

    if "COMMENT" in cat:
        comment += 1
        continue

    if mode == "withoutString":
        if "STRING" in cat:
            stringstart = line.find("\"")
            content = line[stringstart + 1:-2]
            content = "\"string\""
    if "NL" in cat or "NEWLINE" in cat:
        pythondata += "\n"
    elif "INDENT" in cat:
        pythondata += "  " * content.count('t')
    else:
        pythondata += " " + content

    # Save in parts to reduce computational load
    if count > 1000000:
        print("saving part " + str(part) + " (" + mode + ") " + str(totalcount))
        with open('pythontraining' + "_" + mode + "_" + str(part), 'w') as outfile:
            outfile.write(pythondata)
        pythondata = ""
        part += 1
        count = 0

with open('pythontraining' + "_" + mode + "_" + str(part), 'w') as outfile:
    outfile.write(pythondata)
